{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering\n"
      ],
      "metadata": {
        "id": "i5HRt-DaPmAQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?\n",
        "\n",
        "A parameter is a variable used in a function or model to control its behavior.\n",
        "In machine learning, parameters are learned values (like weights in linear regression).\n",
        "\n",
        "2. What is correlation?\n",
        "\n",
        "Correlation measures the strength and direction of the relationship between two variables.\n",
        "It ranges from -1 to +1.\n",
        "\n",
        "3. What does negative correlation mean?\n",
        "\n",
        "Negative correlation means that when one variable increases, the other decreases.\n",
        "Example: Increase in exercise → decrease in weight.\n",
        "\n",
        "4. Define Machine Learning. What are its main components?\n",
        "\n",
        "Machine Learning is a method where computers learn patterns from data without being explicitly programmed.\n",
        "\n",
        "Main components:\n",
        "\n",
        "Dataset\n",
        "\n",
        "Features (inputs)\n",
        "\n",
        "Model\n",
        "\n",
        "Training process\n",
        "\n",
        "Loss function\n",
        "\n",
        "Optimizer\n",
        "\n",
        "Evaluation metrics\n",
        "\n",
        "5. How does loss value help in determining whether the model is good or not?\n",
        "\n",
        "Loss value measures how far the model’s predictions are from the actual values.\n",
        "Lower loss = better model performance.\n",
        "\n",
        "6. What are continuous and categorical variables?\n",
        "\n",
        "Continuous variables: numeric values with infinite possibilities (height, weight, salary).\n",
        "\n",
        "Categorical variables: labels or categories (gender, city, color).\n",
        "\n",
        "7. How do we handle categorical variables in Machine Learning? Common techniques:\n",
        "\n",
        "Label Encoding\n",
        "\n",
        "One-Hot Encoding\n",
        "\n",
        "Ordinal Encoding\n",
        "\n",
        "Binary Encoding\n",
        "\n",
        "Target Encoding\n",
        "\n",
        "8. What do you mean by training and testing a dataset?\n",
        "\n",
        "Training dataset: used to teach the model patterns.\n",
        "\n",
        "Testing dataset: used to evaluate how well the model performs on new unseen data.\n",
        "\n",
        "9. What is sklearn.preprocessing?\n",
        "\n",
        "A module in scikit-learn containing tools for data transformation such as encoding, scaling, normalization.\n",
        "\n",
        "10. What is a Test set?\n",
        "\n",
        "A part of the dataset used to evaluate the final model after training.\n",
        "\n",
        "11. How do we split data for model fitting in Python?\n",
        "\n",
        "Using scikit-learn’s train_test_split:\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "12. How do you approach a Machine Learning problem?\n",
        "\n",
        "Understand the problem\n",
        "\n",
        "Collect data\n",
        "\n",
        "Clean and preprocess data\n",
        "\n",
        "Perform EDA\n",
        "\n",
        "Choose a model\n",
        "\n",
        "Train the model\n",
        "\n",
        "Evaluate performance\n",
        "\n",
        "Tune hyperparameters\n",
        "\n",
        "Deploy model\n",
        "\n",
        "13. Why do we perform EDA before model fitting?\n",
        "\n",
        "EDA helps understand patterns, missing values, correlations, and outliers.\n",
        "It helps select features and improves model performance.\n",
        "\n",
        "14. What is correlation?\n",
        "\n",
        "Correlation shows how two variables are related.\n",
        "(Repeated question — same as question 2.)\n",
        "\n",
        "15. What does negative correlation mean?\n",
        "\n",
        "If one variable increases while the other decreases, correlation is negative.\n",
        "(Repeated — same as question 3.)\n",
        "\n",
        "16. How can you find correlation between variables in Python?\n",
        "\n",
        "Using Pandas:\n",
        "\n",
        "df.corr()\n",
        "\n",
        "\n",
        "With visualization:\n",
        "\n",
        "import seaborn as sns\n",
        "sns.heatmap(df.corr(), annot=True)\n",
        "\n",
        "17. What is causation? Difference between correlation and causation.\n",
        "\n",
        "Causation means one variable directly affects another.\n",
        "\n",
        "Difference:\n",
        "\n",
        "Correlation: two variables move together.\n",
        "\n",
        "Causation: one variable causes the change.\n",
        "\n",
        "Example:\n",
        "Ice cream sales and drowning cases correlate, but ice cream does not cause drowning.\n",
        "Hot weather causes both.\n",
        "\n",
        "18. What is an Optimizer? Types of optimizers.\n",
        "\n",
        "An optimizer reduces the loss by updating model parameters.\n",
        "\n",
        "Types:\n",
        "\n",
        "SGD (Stochastic Gradient Descent) – updates weights using gradient.\n",
        "\n",
        "Momentum – accelerates SGD using past gradients.\n",
        "\n",
        "Adam – adaptive learning rate optimizer.\n",
        "\n",
        "RMSProp – reduces oscillations with adaptive rate.\n",
        "\n",
        "19. What is sklearn.linear_model?\n",
        "\n",
        "A scikit-learn module containing linear models such as LinearRegression, LogisticRegression, Ridge, Lasso.\n",
        "\n",
        "20. What does model.fit() do? What arguments are needed?\n",
        "\n",
        "model.fit() trains the machine learning model.\n",
        "\n",
        "Arguments required:\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "21. What does model.predict() do? What arguments are needed?\n",
        "\n",
        "model.predict() makes predictions on new data.\n",
        "\n",
        "Arguments required:\n",
        "\n",
        "model.predict(X_test)\n",
        "\n",
        "22. What are continuous and categorical variables?\n",
        "\n",
        "(Repeated — same as Question 6.)\n",
        "\n",
        "23. What is feature scaling? How does it help?\n",
        "\n",
        "Feature scaling transforms numerical data to a standard range.\n",
        "It helps improve model performance, convergence, and gradient descent efficiency.\n",
        "\n",
        "24. How do we perform scaling in Python?\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaled = scaler.fit_transform(X)\n",
        "\n",
        "25. What is sklearn.preprocessing?\n",
        "\n",
        "A scikit-learn module for data transformations such as scaling, normalization, encoding.\n",
        "\n",
        "(Repeated — same as Question 9.)\n",
        "\n",
        "26. How do we split data for model fitting in Python?\n",
        "\n",
        "(Repeated — same as Question 11.)\n",
        "\n",
        "27. Explain data encoding.\n",
        "\n",
        "Data encoding converts categorical values into numeric values so algorithms can process them.\n",
        "\n",
        "Methods include:\n",
        "\n",
        "One-hot encoding\n",
        "\n",
        "Label encoding\n",
        "\n",
        "Ordinal encoding\n",
        "\n",
        "Binary encoding"
      ],
      "metadata": {
        "id": "lwlhj2w8PpxP"
      }
    }
  ]
}